{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kitt/miniconda3/envs/trans/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing net with embedding mobilenet_v3_large\n",
      "# Intel train samples: 300\n",
      "# Intel dev samples: 120\n",
      "# Intel test samples: 1800\n",
      "Data initialized: n = 1280, m = 6, pt = 300, pk = 1800, labels: {0: 'buildings', 1: 'forest', 2: 'glacier', 3: 'mountain', 4: 'sea', 5: 'street'}\n",
      "Mean embedding time: 0.0358343007328274 += 0.009211131600370629\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from net_i2l import NetIntel\n",
    "\n",
    "\n",
    "nets = {}\n",
    "#nets_names = ('resnet-18', 'alexnet', 'vgg', 'densenet', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b2', 'efficientnet_b3', 'efficientnet_b4', 'efficientnet_b5', 'efficientnet_b6', 'efficientnet_b7')\n",
    "nets_names = ('mobilenet_v3_large',)\n",
    "for net_name in nets_names:\n",
    "    print(f'Processing net with embedding {net_name}')\n",
    "    nets[net_name] = NetIntel(embedding=net_name)\n",
    "    print(f'Mean embedding time: {np.mean(nets[net_name].stats[\"emb_times\"])} += {np.std(nets[net_name].stats[\"emb_times\"])}')\n",
    "\n",
    "def eval(net, net_name):\n",
    "    print(f'Evaluation of net {net_name}')\n",
    "\n",
    "    net.model.eval()\n",
    "    loss_list = []\n",
    "    oks = []\n",
    "    wrongs = []\n",
    "    n_correct = 0\n",
    "    n_fail = 0\n",
    "    for x, y_true, sample, label in net.data.loader(group='test', batch_size=1):\n",
    "        \n",
    "        y_pred = net.model(x)\n",
    "        loss_list.append(net.trainer.criterion(y_pred, y_true).data)\n",
    "        \n",
    "        target_pred = torch.argmax(y_pred).item()\n",
    "        if target_pred == y_true[0].item():\n",
    "            n_correct += 1\n",
    "            oks.append((sample[0], label[0]))\n",
    "        else:\n",
    "            n_fail += 1\n",
    "            wrongs.append((sample[0], label[0], net.data.target2label[target_pred]))\n",
    "\n",
    "    acc = n_correct / (n_correct + n_fail)\n",
    "    loss = np.mean([l.item() for l in loss_list])\n",
    "\n",
    "\n",
    "    print(f'Loss: {loss}, Acc: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from net_i2l import I2LModel\n",
    "\n",
    "# Reinit\n",
    "for net_name, net in nets.items():\n",
    "    net.model = I2LModel(net.data.n, net.hidden, net.data.m)\n",
    "    net.trainer.reinit_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " == Learning net mobilenet_v3_large\n",
      "Early stopping, dev_loss tail: [0.22011072747409344, 0.22553562000393867, 0.21926244953647256, 0.2381633184850216, 0.2414576644077897, 0.21964311716146767, 0.22042589401826262, 0.22075440594926476, 0.24166752956807613]\n",
      "Final train loss: 0.0385642026207949, dev loss: 0.2766927513293922\n",
      "= last epoch: 34\n",
      "= train time: 0.8004870414733887\n",
      "= train loss: 0.0385642026207949\n",
      "= dev loss: 0.2766927513293922\n",
      "Evaluation of net mobilenet_v3_large\n",
      "Loss: 0.2588300538226031, Acc: 0.915\n"
     ]
    }
   ],
   "source": [
    "for net_name, net in nets.items():\n",
    "    print(f'\\n\\n == Learning net {net_name}')\n",
    "    net.learn(epochs=1500, patience=10)\n",
    "    print(f'= last epoch: {net.stats[\"last_epoch\"]}')\n",
    "    print(f'= train time: {net.stats[\"train_time\"]}')\n",
    "    print(f'= train loss: {net.stats[\"train_loss_list\"][-1]}')\n",
    "    print(f'= dev loss: {net.stats[\"val_loss_list\"][-1]}')\n",
    "    eval(net, net_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mobilenetv3_large_075', 'mobilenetv3_large_100', 'mobilenetv3_large_100_miil', 'mobilenetv3_large_100_miil_in21k', 'tf_mobilenetv3_large_075', 'tf_mobilenetv3_large_100', 'tf_mobilenetv3_large_minimal_100']\n",
      "(1280,)\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "from timm.data.config import resolve_data_config\n",
    "print([m for m in timm.list_models() if 'mobilenetv3_large' in m])\n",
    "\n",
    "img = Image.open(urlopen(\n",
    "    'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'\n",
    "))\n",
    "\n",
    "model = timm.create_model(\n",
    "    'mobilenetv3_large_100_miil_in21k',\n",
    "    pretrained=True,\n",
    "    num_classes=0,  # remove classifier nn.Linear\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = resolve_data_config(args={}, model=model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "#output = model(transforms(img).unsqueeze(0))  # output is (batch_size, num_features) shaped tensor\n",
    "\n",
    "# or equivalently (without needing to set num_classes=0)\n",
    "\n",
    "output = model.forward_features(transforms(img).unsqueeze(0))\n",
    "# output is unpooled, a (1, 960, 7, 7) shaped tensor\n",
    "\n",
    "output = model.forward_head(output, pre_logits=True)\n",
    "# output is a (1, num_features) shaped tensor\n",
    "\n",
    "print(output.detach().flatten().numpy().shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
